{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "- Check for 3 models which number of features for TfIdf will be sufficient with respect to number of ngrams\n",
    "    - Save Acc, Prec, Rec and F1\n",
    "    - Save the result\n",
    "- For given max features and ngrams run TPOT Classifier\n",
    "- Write a pipeline which for at least 10 models search for optimal parameters for such data preprocessors:\n",
    "    - Bag of Words\n",
    "    - TfIdf\n",
    "    - Normal tokens\n",
    "    - Lemmatized tokens\n",
    "    - LabelBinarize\n",
    "    - OneHotEncoding\n",
    "- Try to improve best of 3 models via hyperparameter tuning and dimensionality reduction\n",
    "- Use ensemble methods like \n",
    "    - stacking classifier\n",
    "    - voting classifier\n",
    "- Write and evaluate a simple neural network with embedding tensorflow and keras tuner \n",
    "- Use word2vec to your neural network\n",
    "- Calculate additional features from NER, POS, Sentiment analysis, KMeans, Topic modelling\n",
    "- Write a neural network which accpets new inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = os.path.join('..', 'data', 'interim', 'prepared_data_Kamil.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['language', 'lyrics']\n",
    "unstructured_columns = ['tokens', 'entities', 'pos_tokens', 'tokens_lemma']\n",
    "df = pd.read_csv(path_to_data)\n",
    "\n",
    "# Drop unused columns\n",
    "df.drop(drop_columns, axis=1, inplace=True)\n",
    "\n",
    "# Converting columns with lists/dicts to usable structure\n",
    "for column in unstructured_columns:\n",
    "    df[column] = df[column].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'evening': 'TIME', 'Tryna': 'PERSON', 'Cause': 'ORG'}\n"
     ]
    }
   ],
   "source": [
    "print(df['entities'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['entities'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns != 'genre'], df['genre'],\n",
    "                                                    random_state=7, stratify=df['genre'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for optimal Data Preprocessing params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = X_train.head(50)['tokens_lemma']\n",
    "X_temp = X_temp.apply(lambda x: ' '.join(x))\n",
    "y_temp = y_train.head(50)\n",
    "\n",
    "onehot= LabelEncoder()\n",
    "\n",
    "y_temp = onehot.fit_transform(y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'ngram_range': [(1, 1), (1, 2)],\n",
    "              'max_features': [30, 40]}\n",
    "\n",
    "models = {'Random Forest': RandomForestClassifier(max_depth=30),\n",
    "          'XGBoost Classifier': xgb.XGBClassifier(max_depth=30),\n",
    "          'Gaussian Naive Bayes': GaussianNB()}\n",
    "\n",
    "cv_kwargs = {'cv': 2,\n",
    "             'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_tfidf_params(X, y, param_grid, models, \n",
    "                              cv_kwargs=None, random_state=7):\n",
    "    \n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    scoring = ['accuracy', 'recall_weighted', 'precision_weighted', 'f1_weighted']\n",
    "    \n",
    "    params_combinations = [{'ngram_range': ngram, 'max_features': max_feature}\n",
    "                          for ngram in param_grid['ngram_range'] \n",
    "                          for max_feature in param_grid['max_features']]\n",
    "    results = _create_results()\n",
    "    for params in params_combinations:\n",
    "        \n",
    "        tfidf = TfidfVectorizer(**params)\n",
    "        X_tfidf = tfidf.fit_transform(X).toarray()\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            cv = cross_validate(model, X_tfidf, y, scoring=scoring, **cv_kwargs)\n",
    "            round_cv_results(cv)\n",
    "            temp = cv_to_dataframe(cv, name, **params)\n",
    "            results = results.append(temp, ignore_index=True)\n",
    "    return results\n",
    "        \n",
    "def _create_results():    \n",
    "    return pd.DataFrame({'Name': [],\n",
    "                         'max_features': [],\n",
    "                         'ngram_range': [],\n",
    "                         'Accuracy': [],\n",
    "                         'Recall': [],\n",
    "                         'Precision': [],\n",
    "                         'F1': []})\n",
    "\n",
    "def cv_to_dataframe(cv, name, max_features=None, ngram_range=None):\n",
    "    return pd.DataFrame({'Name': [name],\n",
    "                         'max_features': [max_features],\n",
    "                         'ngram_range': [ngram_range],\n",
    "                         'Accuracy': [cv['test_accuracy']],\n",
    "                         'Recall': [cv['test_recall_weighted']],\n",
    "                         'Precision': [cv['test_precision_weighted']],\n",
    "                         'F1': [cv['test_f1_weighted']]})\n",
    "\n",
    "def round_cv_results(cv):\n",
    "    for key in ['test_accuracy', 'test_recall_weighted', 'test_precision_weighted', 'test_f1_weighted']:\n",
    "        values = cv[key]\n",
    "        cv[key] = [np.round(i, 2) for i in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = find_optimal_tfidf_params(X_temp, y_temp, param_grid, models, cv_kwargs = cv_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>max_features</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>30.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>[0.12, 0.16]</td>\n",
       "      <td>[0.12, 0.16]</td>\n",
       "      <td>[0.1, 0.08]</td>\n",
       "      <td>[0.1, 0.11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>30.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>[0.08, 0.08]</td>\n",
       "      <td>[0.08, 0.08]</td>\n",
       "      <td>[0.07, 0.06]</td>\n",
       "      <td>[0.07, 0.06]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>30.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>[0.12, 0.2]</td>\n",
       "      <td>[0.12, 0.2]</td>\n",
       "      <td>[0.07, 0.14]</td>\n",
       "      <td>[0.08, 0.14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>40.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>[0.16, 0.12]</td>\n",
       "      <td>[0.16, 0.12]</td>\n",
       "      <td>[0.05, 0.05]</td>\n",
       "      <td>[0.08, 0.07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>40.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>[0.08, 0.16]</td>\n",
       "      <td>[0.08, 0.16]</td>\n",
       "      <td>[0.06, 0.1]</td>\n",
       "      <td>[0.07, 0.12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>40.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>[0.16, 0.28]</td>\n",
       "      <td>[0.16, 0.28]</td>\n",
       "      <td>[0.22, 0.16]</td>\n",
       "      <td>[0.17, 0.17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>30.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>[0.12, 0.04]</td>\n",
       "      <td>[0.12, 0.04]</td>\n",
       "      <td>[0.05, 0.03]</td>\n",
       "      <td>[0.07, 0.04]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>30.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>[0.16, 0.12]</td>\n",
       "      <td>[0.16, 0.12]</td>\n",
       "      <td>[0.14, 0.12]</td>\n",
       "      <td>[0.14, 0.12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>30.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>[0.08, 0.24]</td>\n",
       "      <td>[0.08, 0.24]</td>\n",
       "      <td>[0.06, 0.14]</td>\n",
       "      <td>[0.06, 0.15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>40.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>[0.16, 0.04]</td>\n",
       "      <td>[0.16, 0.04]</td>\n",
       "      <td>[0.1, 0.02]</td>\n",
       "      <td>[0.12, 0.02]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>40.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>[0.16, 0.16]</td>\n",
       "      <td>[0.16, 0.16]</td>\n",
       "      <td>[0.13, 0.11]</td>\n",
       "      <td>[0.14, 0.13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>40.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>[0.16, 0.28]</td>\n",
       "      <td>[0.16, 0.28]</td>\n",
       "      <td>[0.22, 0.16]</td>\n",
       "      <td>[0.17, 0.17]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  max_features ngram_range      Accuracy  \\\n",
       "0          Random Forest          30.0      (1, 1)  [0.12, 0.16]   \n",
       "1     XGBoost Classifier          30.0      (1, 1)  [0.08, 0.08]   \n",
       "2   Gaussian Naive Bayes          30.0      (1, 1)   [0.12, 0.2]   \n",
       "3          Random Forest          40.0      (1, 1)  [0.16, 0.12]   \n",
       "4     XGBoost Classifier          40.0      (1, 1)  [0.08, 0.16]   \n",
       "5   Gaussian Naive Bayes          40.0      (1, 1)  [0.16, 0.28]   \n",
       "6          Random Forest          30.0      (1, 2)  [0.12, 0.04]   \n",
       "7     XGBoost Classifier          30.0      (1, 2)  [0.16, 0.12]   \n",
       "8   Gaussian Naive Bayes          30.0      (1, 2)  [0.08, 0.24]   \n",
       "9          Random Forest          40.0      (1, 2)  [0.16, 0.04]   \n",
       "10    XGBoost Classifier          40.0      (1, 2)  [0.16, 0.16]   \n",
       "11  Gaussian Naive Bayes          40.0      (1, 2)  [0.16, 0.28]   \n",
       "\n",
       "          Recall     Precision            F1  \n",
       "0   [0.12, 0.16]   [0.1, 0.08]   [0.1, 0.11]  \n",
       "1   [0.08, 0.08]  [0.07, 0.06]  [0.07, 0.06]  \n",
       "2    [0.12, 0.2]  [0.07, 0.14]  [0.08, 0.14]  \n",
       "3   [0.16, 0.12]  [0.05, 0.05]  [0.08, 0.07]  \n",
       "4   [0.08, 0.16]   [0.06, 0.1]  [0.07, 0.12]  \n",
       "5   [0.16, 0.28]  [0.22, 0.16]  [0.17, 0.17]  \n",
       "6   [0.12, 0.04]  [0.05, 0.03]  [0.07, 0.04]  \n",
       "7   [0.16, 0.12]  [0.14, 0.12]  [0.14, 0.12]  \n",
       "8   [0.08, 0.24]  [0.06, 0.14]  [0.06, 0.15]  \n",
       "9   [0.16, 0.04]   [0.1, 0.02]  [0.12, 0.02]  \n",
       "10  [0.16, 0.16]  [0.13, 0.11]  [0.14, 0.13]  \n",
       "11  [0.16, 0.28]  [0.22, 0.16]  [0.17, 0.17]  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logistic regerssion\n",
    "- random forest\n",
    "- xgboost\n",
    "- sgd class\n",
    "- svc\n",
    "- knn\n",
    "- gaussiannb\n",
    "- adaboost\n",
    "- MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29176610978520284"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X, y_train)\n",
    "model.score(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "score() missing 2 required positional arguments: 'X' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RAFA~1\\AppData\\Local\\Temp/ipykernel_4220/3947582719.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: score() missing 2 required positional arguments: 'X' and 'y'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>genre</th>\n",
       "      <th>tokens</th>\n",
       "      <th>entities</th>\n",
       "      <th>pos_tokens</th>\n",
       "      <th>tokens_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Bay</td>\n",
       "      <td>Let It Go</td>\n",
       "      <td>73</td>\n",
       "      <td>rock</td>\n",
       "      <td>[walking, home, talking, loads, seeing, shows,...</td>\n",
       "      <td>{'evening': 'TIME', 'Tryna': 'PERSON', 'Cause'...</td>\n",
       "      <td>[(walking, v), (home, n), (talking, v), (loads...</td>\n",
       "      <td>[walk, home, talk, load, see, show, even, clot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bonobo</td>\n",
       "      <td>From You</td>\n",
       "      <td>67</td>\n",
       "      <td>jazz</td>\n",
       "      <td>[gone, like, changing, seasons, alright, alrig...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[(gone, v), (like, n), (changing, v), (seasons...</td>\n",
       "      <td>[go, like, change, season, alright, alright, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lee Brice</td>\n",
       "      <td>One Of Them Girls</td>\n",
       "      <td>69</td>\n",
       "      <td>country</td>\n",
       "      <td>[one, girls, peels, bud, light, label, might, ...</td>\n",
       "      <td>{'Kinda': 'PERSON', 'one': 'CARDINAL', 'all ni...</td>\n",
       "      <td>[(one, n), (girls, n), (peels, n), (bud, v), (...</td>\n",
       "      <td>[one, girl, peel, bud, light, label, might, ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andy Gibb</td>\n",
       "      <td>I Just Want To Be Your Everything</td>\n",
       "      <td>62</td>\n",
       "      <td>disco</td>\n",
       "      <td>[long, finding, long, feeling, feel, strong, g...</td>\n",
       "      <td>{'Build': 'FAC'}</td>\n",
       "      <td>[(long, r), (finding, v), (long, r), (feeling,...</td>\n",
       "      <td>[long, find, long, feel, feel, strong, girl, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth, Wind &amp; Fire</td>\n",
       "      <td>You Want My Love</td>\n",
       "      <td>61</td>\n",
       "      <td>jazz</td>\n",
       "      <td>[got, ta, say, much, tell, love, means, someth...</td>\n",
       "      <td>{'Don': 'PERSON', 'Lies': 'PERSON'}</td>\n",
       "      <td>[(got, v), (ta, n), (say, v), (much, r), (tell...</td>\n",
       "      <td>[get, ta, say, much, tell, love, mean, somethi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist_name                         track_name  popularity    genre  \\\n",
       "0           James Bay                          Let It Go          73     rock   \n",
       "1              Bonobo                           From You          67     jazz   \n",
       "2           Lee Brice                  One Of Them Girls          69  country   \n",
       "3           Andy Gibb  I Just Want To Be Your Everything          62    disco   \n",
       "4  Earth, Wind & Fire                   You Want My Love          61     jazz   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [walking, home, talking, loads, seeing, shows,...   \n",
       "1  [gone, like, changing, seasons, alright, alrig...   \n",
       "2  [one, girls, peels, bud, light, label, might, ...   \n",
       "3  [long, finding, long, feeling, feel, strong, g...   \n",
       "4  [got, ta, say, much, tell, love, means, someth...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'evening': 'TIME', 'Tryna': 'PERSON', 'Cause'...   \n",
       "1                                                 {}   \n",
       "2  {'Kinda': 'PERSON', 'one': 'CARDINAL', 'all ni...   \n",
       "3                                   {'Build': 'FAC'}   \n",
       "4                {'Don': 'PERSON', 'Lies': 'PERSON'}   \n",
       "\n",
       "                                          pos_tokens  \\\n",
       "0  [(walking, v), (home, n), (talking, v), (loads...   \n",
       "1  [(gone, v), (like, n), (changing, v), (seasons...   \n",
       "2  [(one, n), (girls, n), (peels, n), (bud, v), (...   \n",
       "3  [(long, r), (finding, v), (long, r), (feeling,...   \n",
       "4  [(got, v), (ta, n), (say, v), (much, r), (tell...   \n",
       "\n",
       "                                        tokens_lemma  \n",
       "0  [walk, home, talk, load, see, show, even, clot...  \n",
       "1  [go, like, change, season, alright, alright, s...  \n",
       "2  [one, girl, peel, bud, light, label, might, ru...  \n",
       "3  [long, find, long, feel, feel, strong, girl, t...  \n",
       "4  [get, ta, say, much, tell, love, mean, somethi...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gauss_spotify",
   "language": "python",
   "name": "gauss_spotify"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

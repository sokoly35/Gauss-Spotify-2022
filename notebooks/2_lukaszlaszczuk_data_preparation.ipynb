{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/kamilabystron/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kamilabystron/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kamilabystron/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kamilabystron/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/kamilabystron/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/kamilabystron/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langdetect import detect\n",
    "\n",
    "import spacy\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english')\n",
    "NER = spacy.load(\"en_core_web_sm\")\n",
    "LEMMATIZER = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('..', 'data', 'data.csv')\n",
    "df = pd.read_csv(data_path).drop_duplicates(subset='lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7392, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_errors(df):\n",
    "    df = df[~df.lyrics.str.startswith('Error in')].reset_index(drop=True)\n",
    "    df.lyrics = df.lyrics.apply(lambda x: x.rstrip('EmbedShare URLCopyEmbedCopy'))\n",
    "    df.lyrics = df.lyrics.replace('\\d{,}$', '', regex=True)\n",
    "    return df\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'unknown'\n",
    "    \n",
    "def tokenize_lyrics(df):\n",
    "    df.lyrics = df.lyrics.str.replace('\\W+', ' ', regex=True)\n",
    "    df['tokens'] = df.lyrics.str.lower().apply(lambda x: word_tokenize(x))\n",
    "    return df\n",
    "\n",
    "def remove_stopwords(tokens, stopwords):\n",
    "    return [el for el in tokens if el not in stopwords]\n",
    "\n",
    "def get_entities(text, ner):\n",
    "    entities = {ent.text: ent.label_ for ent in ner(text).ents}\n",
    "    return entities\n",
    "    \n",
    "def get_wordnet_pos(tokens):\n",
    "    pos_tokens = nltk.pos_tag(tokens)\n",
    "    pos_tokens_wordnet = [(el[0], map_pos_wordnet(el[1])) for el in pos_tokens]\n",
    "    return pos_tokens_wordnet\n",
    "\n",
    "def map_pos_wordnet(token):\n",
    "    if token[0].startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif token[0].startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif token[0].startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif token[0].startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "def lemmatize_tokens(pos_tokens, lemmatizer):\n",
    "    return [lemmatizer.lemmatize(token[0], pos=token[1]) for token in pos_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(df, ner, lemmatizer, stopwords):\n",
    "    df = drop_errors(df)\n",
    "    df['language'] = df['lyrics'].apply(detect_language)\n",
    "    df = df[df['language'] == 'en']\n",
    "    df = tokenize_lyrics(df)\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: remove_stopwords(x, stopwords))\n",
    "    df['entities'] = df['lyrics'].apply(lambda x: get_entities(x, ner))\n",
    "    df['pos_tokens'] = df['tokens'].apply(lambda x: get_wordnet_pos(x))\n",
    "    df['tokens_lemma'] = df['pos_tokens'].apply(lambda x: lemmatize_tokens(x, lemmatizer))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_dataframe(df, NER, LEMMATIZER, STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>tokens</th>\n",
       "      <th>entities</th>\n",
       "      <th>pos_tokens</th>\n",
       "      <th>tokens_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Bay</td>\n",
       "      <td>Let It Go</td>\n",
       "      <td>73</td>\n",
       "      <td>rock</td>\n",
       "      <td>From walking home and talking loads To seeing ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[walking, home, talking, loads, seeing, shows,...</td>\n",
       "      <td>{'evening': 'TIME', 'Tryna': 'PERSON', 'Cause'...</td>\n",
       "      <td>[(walking, v), (home, n), (talking, v), (loads...</td>\n",
       "      <td>[walk, home, talk, load, see, show, even, clot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bonobo</td>\n",
       "      <td>From You</td>\n",
       "      <td>67</td>\n",
       "      <td>jazz</td>\n",
       "      <td>Gone like changing seasons Alright alright You...</td>\n",
       "      <td>en</td>\n",
       "      <td>[gone, like, changing, seasons, alright, alrig...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[(gone, v), (like, n), (changing, v), (seasons...</td>\n",
       "      <td>[go, like, change, season, alright, alright, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lee Brice</td>\n",
       "      <td>One Of Them Girls</td>\n",
       "      <td>69</td>\n",
       "      <td>country</td>\n",
       "      <td>Are you one of them girls that peels off the B...</td>\n",
       "      <td>en</td>\n",
       "      <td>[one, girls, peels, bud, light, label, might, ...</td>\n",
       "      <td>{'Kinda': 'PERSON', 'one': 'CARDINAL', 'all ni...</td>\n",
       "      <td>[(one, n), (girls, n), (peels, n), (bud, v), (...</td>\n",
       "      <td>[one, girl, peel, bud, light, label, might, ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andy Gibb</td>\n",
       "      <td>I Just Want To Be Your Everything</td>\n",
       "      <td>62</td>\n",
       "      <td>disco</td>\n",
       "      <td>For so long You and me been finding each other...</td>\n",
       "      <td>en</td>\n",
       "      <td>[long, finding, long, feeling, feel, strong, g...</td>\n",
       "      <td>{'Build': 'FAC'}</td>\n",
       "      <td>[(long, r), (finding, v), (long, r), (feeling,...</td>\n",
       "      <td>[long, find, long, feel, feel, strong, girl, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth, Wind &amp; Fire</td>\n",
       "      <td>You Want My Love</td>\n",
       "      <td>61</td>\n",
       "      <td>jazz</td>\n",
       "      <td>You ain t gotta say much I can tell that love ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[got, ta, say, much, tell, love, means, someth...</td>\n",
       "      <td>{'Don': 'PERSON', 'Lies': 'PERSON'}</td>\n",
       "      <td>[(got, v), (ta, n), (say, v), (much, r), (tell...</td>\n",
       "      <td>[get, ta, say, much, tell, love, mean, somethi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist_name                         track_name  popularity    genre  \\\n",
       "0           James Bay                          Let It Go          73     rock   \n",
       "1              Bonobo                           From You          67     jazz   \n",
       "2           Lee Brice                  One Of Them Girls          69  country   \n",
       "3           Andy Gibb  I Just Want To Be Your Everything          62    disco   \n",
       "4  Earth, Wind & Fire                   You Want My Love          61     jazz   \n",
       "\n",
       "                                              lyrics language  \\\n",
       "0  From walking home and talking loads To seeing ...       en   \n",
       "1  Gone like changing seasons Alright alright You...       en   \n",
       "2  Are you one of them girls that peels off the B...       en   \n",
       "3  For so long You and me been finding each other...       en   \n",
       "4  You ain t gotta say much I can tell that love ...       en   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [walking, home, talking, loads, seeing, shows,...   \n",
       "1  [gone, like, changing, seasons, alright, alrig...   \n",
       "2  [one, girls, peels, bud, light, label, might, ...   \n",
       "3  [long, finding, long, feeling, feel, strong, g...   \n",
       "4  [got, ta, say, much, tell, love, means, someth...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'evening': 'TIME', 'Tryna': 'PERSON', 'Cause'...   \n",
       "1                                                 {}   \n",
       "2  {'Kinda': 'PERSON', 'one': 'CARDINAL', 'all ni...   \n",
       "3                                   {'Build': 'FAC'}   \n",
       "4                {'Don': 'PERSON', 'Lies': 'PERSON'}   \n",
       "\n",
       "                                          pos_tokens  \\\n",
       "0  [(walking, v), (home, n), (talking, v), (loads...   \n",
       "1  [(gone, v), (like, n), (changing, v), (seasons...   \n",
       "2  [(one, n), (girls, n), (peels, n), (bud, v), (...   \n",
       "3  [(long, r), (finding, v), (long, r), (feeling,...   \n",
       "4  [(got, v), (ta, n), (say, v), (much, r), (tell...   \n",
       "\n",
       "                                        tokens_lemma  \n",
       "0  [walk, home, talk, load, see, show, even, clot...  \n",
       "1  [go, like, change, season, alright, alright, s...  \n",
       "2  [one, girl, peel, bud, light, label, might, ru...  \n",
       "3  [long, find, long, feel, feel, strong, girl, t...  \n",
       "4  [get, ta, say, much, tell, love, mean, somethi...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join('..', 'data', 'prepared_data.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
